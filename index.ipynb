{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self , feature=None , threshold=None , left=None , right=None , gain=None , value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.gain = gain\n",
    "        self.value = value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, min_samples, max_depth):\n",
    "        self.min_samples = min_samples\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def split_data(self, dataset, feature, threshold):\n",
    "        left_dataset = dataset[dataset[:, feature] <= threshold]\n",
    "        right_dataset = dataset[dataset[:, feature] > threshold]\n",
    "        return left_dataset, right_dataset\n",
    "\n",
    "    def entropy(self, y):\n",
    "        labels, counts = np.unique(y, return_counts=True)\n",
    "        probabilities = counts / len(y)\n",
    "        return -np.sum(probabilities * np.log(probabilities))\n",
    "\n",
    "    def information_gain(self, parent, left, right):\n",
    "        parent_entropy = self.entropy(parent)\n",
    "        total_samples = len(left) + len(right)\n",
    "\n",
    "        weighted_entropy = (len(left) / total_samples) * self.entropy(left) + \\\n",
    "                           (len(right) / total_samples) * self.entropy(right)\n",
    "\n",
    "        return parent_entropy - weighted_entropy\n",
    "\n",
    "    def best_split(self, dataset, num_features):\n",
    "        best_split = {'gain': -1, 'feature': None, 'threshold': None}\n",
    "\n",
    "        for idx in range(num_features):\n",
    "            feature_values = dataset[:, idx]\n",
    "            thresholds = np.unique(feature_values)\n",
    "            for threshold in thresholds:\n",
    "                left_dataset, right_dataset = self.split_data(\n",
    "                    dataset, idx, threshold)\n",
    "\n",
    "                if len(left_dataset) > 0 and len(right_dataset) > 0:\n",
    "                    parent, left, right = dataset[:, -1], left_dataset[:, -1], right_dataset[:, -1]\n",
    "                    gain = self.information_gain(parent, left, right)\n",
    "\n",
    "                    if gain > best_split[\"gain\"]:\n",
    "                        best_split.update({\n",
    "                            \"feature\": idx,\n",
    "                            \"threshold\": threshold,\n",
    "                            \"left_dataset\": left_dataset,\n",
    "                            \"right_dataset\": right_dataset,\n",
    "                            \"gain\": gain\n",
    "                        })\n",
    "\n",
    "        return None if best_split[\"gain\"] == -1 else best_split\n",
    "\n",
    "    def calculate_leaf_value(self, y):\n",
    "        y = list(y)\n",
    "        return max(y, key=y.count)\n",
    "\n",
    "    def build_tree(self, dataset, current_depth=0):\n",
    "        X, y = dataset[:, :-1], dataset[:, -1]\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        if n_samples >= self.min_samples and current_depth <= self.max_depth:\n",
    "            best_split = self.best_split(dataset, n_features)\n",
    "            if best_split is not None:\n",
    "                left_node = self.build_tree(\n",
    "                    best_split[\"left_dataset\"], current_depth + 1)\n",
    "                right_node = self.build_tree(\n",
    "                    best_split[\"right_dataset\"], current_depth + 1)\n",
    "                return Node(feature=best_split[\"feature\"], threshold=best_split[\"threshold\"],\n",
    "                            left=left_node, right=right_node)\n",
    "\n",
    "        # Create a leaf node\n",
    "        leaf_value = self.calculate_leaf_value(y)\n",
    "        return Node(value=leaf_value)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        dataset = np.concatenate((X, y.reshape(-1, 1)), axis=1)\n",
    "        self.root = self.build_tree(dataset)\n",
    "\n",
    "    def make_prediction(self, x, node):\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "\n",
    "        feature_value = x[node.feature]\n",
    "        if feature_value <= node.threshold:\n",
    "            return self.make_prediction(x, node.left)\n",
    "        else:\n",
    "            return self.make_prediction(x, node.right)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self.make_prediction(x, self.root) for x in X])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id               0\n",
      "SepalLengthCm    0\n",
      "SepalWidthCm     0\n",
      "PetalLengthCm    0\n",
      "PetalWidthCm     0\n",
      "Species          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"SepalLengthCm\" , \"SepalWidthCm\" , \"PetalLengthCm\" , \"PetalWidthCm\"]].values\n",
    "y = df[\"Species\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (X - X.mean()) / X.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = int(0.8 * df.shape[0])\n",
    "train_X , train_y = X[:idx] , y[:idx]\n",
    "test_X , test_y = X[idx:] , y[idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTree(min_samples=30 , max_depth=10)\n",
    "model.fit(train_X , train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred =  model.predict(test_X)\n",
    "\n",
    "np.unique(y_pred)\n",
    "\n",
    "\n",
    "accuracy = (np.sum(y_pred == test_y) / len(test_y)) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(83.33333333333334)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
